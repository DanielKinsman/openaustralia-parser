#!/usr/bin/env ruby
#
# Utility for downloading and extracting the main contents body of aph.gov.au pages that contain procedural texts
# Puts the contents into a custom xml file
#
# This is the first step to create a validating xml schema for the data. This is a really good way
# of defining what the structure of the web pages is so that we can write a parser to reformat the
# data into a form that we want.

$:.unshift "#{File.dirname(__FILE__)}/../lib"

require 'mechanize_proxy'
require 'date'

def parse_date(date)
  # Required to workaround long viewstates generated by .NET (whatever that means)
  # See http://code.whytheluckystiff.net/hpricot/ticket/13
  Hpricot.buffer_size = 400000

  agent = MechanizeProxy.new
  agent.cache_subdirectory = date.to_s

  url = "http://parlinfoweb.aph.gov.au/piweb/browse.aspx?path=Chamber%20%3E%20House%20Hansard%20%3E%20#{date.year}%20%3E%20#{date.day}%20#{Date::MONTHNAMES[date.month]}%20#{date.year}"
  begin
    page = agent.get(url)
    # HACK: Don't know why if the page isn't found a return code isn't returned. So, hacking around this.
    if page.title == "ParlInfo Web - Error"
      throw "ParlInfo Web - Error"
    end
  rescue
    puts "Could not retrieve overview page for date #{date}"
    return
  end
  # Structure of the page is such that we are only interested in some of the links
  page.links[30..-4].each do |link|
    parse_sub_day_page(agent.click(link))
  end
end

def extract_metadata_tags(page)
  # Extract metadata tags
  i = 0
  metadata = {}
  while true
    label_tag = page.search("span#dlMetadata__ctl#{i}_Label2").first
    value_tag = page.search("span#dlMetadata__ctl#{i}_Label3").first
    break if label_tag.nil? && value_tag.nil?
    metadata[label_tag.inner_text] = value_tag.inner_text
    i = i + 1
  end
  metadata
end

def parse_sub_day_page(page)
  puts "<page>"
  puts "<meta>"
  extract_metadata_tags(page).each_pair do |key, value|
    e = escape_for_tag_name(key)
    puts "<#{e}>#{value}</#{e}>"
  end
  puts "</meta>"
  puts "<content>#{page.search("div#contentstart")}</content>"
  puts "</page>"
end

def escape_for_tag_name(text)
  text.tr(' ', '-').downcase
end

puts "<hansard>"
parse_date(Date.new(2008, 5, 29))
puts "</hansard>"

